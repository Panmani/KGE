Retrain model on SFM dataset
======

Current Log Summary
------
Oct 31 - Nov 6
```
----- Wrote:
  process.py: added code for loading name lists and misclassified sentences

----- Results:
  Previous model:
    Precision:  0.39204545454545453
    Recall:  0.43125
    F1 score:  0.4107142857142857
    Similar Precision:  0.8579545454545454
    Similar Recall:  0.8830409356725146
    Similar F1 score:  0.8703170028818444

  With tokenization:
    Precision:  0.7386363636363636
    Recall:  0.7975460122699386
    F1 score:  0.7669616519174041
    Similar Precision:  0.8579545454545454
    Similar Recall:  0.8830409356725146
    Similar F1 score:  0.8703170028818444

  With the two name lists and tokenization:
  (Nov_3_examples.txt)
    Precision:  0.7314285714285714
    Recall:  0.7852760736196319
    F1 score:  0.757396449704142
    Similar Precision:  0.8571428571428571
    Similar Recall:  0.872093023255814
    Similar F1 score:  0.8645533141210374

  With misclassified sentences, the two name lists and tokenization:
  (Nov_6_examples.txt)
    Precision:  0.7005347593582888
    Recall:  0.808641975308642
    F1 score:  0.7507163323782235
    Similar Precision:  0.839572192513369
    Similar Recall:  0.9181286549707602
    Similar F1 score:  0.8770949720670391
```

Oct 24 - Oct 31, Ian Ma

Files
------
> process.py:

1. preprocess dataset for convert_format.py by recording info in dicts, which are saved in two pickle files: dataset_labels.pickle, dataset_sentences.pickle
2. convert SFM starter dataset to a format that can be used by the model

>pred.py

generates predictions use the trained model. Before this, run python3 train.py

>eval.py

evaluate the predctions made by model, which are generated by running pred.py

Usage
------
1. Preprocess data
```shell
$ python3 process.py
$ cd SFM_STARTER
$ python3 build_vocab.py
$ python3 build_glove.py
$ cd ..
```

2. Train model
```shell
$ python3 train.py
```

3. Evaluate model
```shell
$ python3 pred.py
$ python3 eval.py
```


Dataset
------
For training, I used 400 sentences from SFM starter dataset and the first 5000 sentences from CONLL2003 training data.

Training
------
Saving dict for global step 3472: acc = 0.92142266, f1 = 0.77824265, global_step = 3472, loss = 7.126516, precision = 0.7237354, recall = 0.84162897
Saving 'checkpoint_path' summary for global step 3472: results/model/model.ckpt-3472

Results
------
Output of [eval.py](eval.py) is included in [Oct_24_examples.txt](Oct_24_examples.txt)
```
Precision:  0.40707964601769914
Recall:  0.46938775510204084
F1 score:  0.4360189573459716
Similar Precision:  0.8495575221238938
Similar Recall:  0.9142857142857143
Similar F1 score:  0.8807339449541286
```

Prediction labels are mapped using this dict, define in [process.py](process.py):
```Python
label_mapping = {'Person':       'PER',
                 'Rank':         'RAN',
                 'Organization': 'ORG',
                 'Title':        'TIT',
                 'Role':         'ROL'}
```
