Retrain model on SFM dataset
======
Oct 24 - Oct 31, Ian Ma

Files
------
> process.py:

1. preprocess dataset for convert_format.py by recording info in dicts, which are saved in two pickle files: dataset_labels.pickle, dataset_sentences.pickle
2. convert SFM starter dataset to a format that can be used by the model

>pred.py

generates predictions use the trained model. Before this, run python3 train.py

>eval.py

evaluate the predctions made by model, which are generated by running pred.py

Usage
------
1. Preprocess data
```shell
$ python3 process.py
$ cd SFM_STARTER
$ python3 build_vocab.py
$ python3 build_glove.py
$ cd ..
```

2. Train model
```shell
$ python3 train.py
```

3. Evaluate model
```shell
$ python3 pred.py
$ python3 eval.py
```


Dataset
------
For training, I used 400 sentences from SFM starter dataset and the first 5000 sentences from CONLL2003 training data.

Training
------
Saving dict for global step 3472: acc = 0.92142266, f1 = 0.77824265, global_step = 3472, loss = 7.126516, precision = 0.7237354, recall = 0.84162897
Saving 'checkpoint_path' summary for global step 3472: results/model/model.ckpt-3472

Results
------
Output of [eval.py](eval.py) is included in [Oct_24_examples.txt](Oct_24_examples.txt)
```
Precision:  0.40707964601769914
Recall:  0.46938775510204084
F1 score:  0.4360189573459716
Similar Precision:  0.8495575221238938
Similar Recall:  0.9142857142857143
Similar F1 score:  0.8807339449541286
```

Prediction labels are mapped using this dict, define in [process.py](process.py):
```Python
label_mapping = {'Person':       'PER',
                 'Rank':         'RAN',
                 'Organization': 'ORG',
                 'Title':        'TIT',
                 'Role':         'ROL'}
```
